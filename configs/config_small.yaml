engine:
  model_path: Qwen/Qwen3-4B-Instruct-2507
  tp_size: 4          # use all 4 GPUs on the node
  trust_remote_code: true

sampling_params:
  temperature: 0.1
  top_p: 1.0
  max_new_tokens: 384
  custom_params:
    chat_template_kwargs: 
      enable_thinking: false

processing_gen_params:
  datasets:
    - path: /capstor/store/cscs/swissai/a127/meditron/datasets/polyglot/english_tiny.jsonl
      type: JSONL
  output_dir: /capstor/store/cscs/swissai/a127/homes/$USER/datasets/english_tiny/shards
  # num_shards: "$SLURM_ARRAY_TASK_COUNT"
  # shard_id: "$SLURM_ARRAY_TASK_ID"
  num_shards: 4
  shard_id: 0
  conversations_field: "conversations"
  batch_size: 64

processing_params:
  inputs:
    - name: text
      key: text
    - name: language
      key: language
    - name: modalities
      key: modalities

  outputs:
    - name: formatted_answer
      type: llm
      output_type: plain
      prompt: |
        Reformat the following in a markdown format without adding anything else:
        ```
        {{ text }}
        ```

  output_schema:
    text: "{{ formatted_answer }}"
    language: "{{ language }}"
    modalities: "{{ modalities }}"
