engine:
  model_path: Qwen/Qwen2.5-VL-7B-Instruct  # Vision-language model
  tp_size: 4          # use all 4 GPUs on the node
  trust_remote_code: true

sampling_params:
  temperature: 0.1
  top_p: 1.0
  max_new_tokens: 512

processing_gen_params:
  datasets:
    - path: /path/to/your/image_dataset  # Update with actual dataset path
      type: loadable
  output_dir: /path/to/output/shards  # Update with desired output path
  num_shards: "$SLURM_ARRAY_TASK_COUNT"
  shard_id: "$SLURM_ARRAY_TASK_ID"
  conversations_field: "conversations"
  batch_size: 32

processing_params:
  inputs:
    - name: image
      key: image  # Path to the image field in your dataset
      type: image  # Indicates this is an image input
      # image_base_path: /path/to/images  # Optional: only needed if dataset has relative paths
    - name: caption
      key: caption  # Path to the caption field in your dataset
      type: text  # Default type for text inputs

  outputs:
    - name: enhanced_caption
      type: llm
      output_type: plain
      prompt: |
        You are provided with an image and its original caption.
        Please enhance the caption to be more descriptive and accurate while maintaining the original meaning.
        Do not add information that is not visible in the image.
        
        Original caption: {caption}

  output_schema:
    image: "{image}"  # Pass through unchanged
    caption: "{enhanced_caption}"  # Use the enhanced caption
